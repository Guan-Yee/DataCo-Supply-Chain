{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab87e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been exported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "# Define the path to the CSV file\n",
    "processed_data_path = os.path.join(current_directory, '..', '..', 'data', 'processed')\n",
    "raw_data_path = os.path.join(current_directory, '..', '..', 'data', 'raw', 'DataCoSupplyChainDataset.csv')\n",
    "\n",
    "df = pd.read_csv(raw_data_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Partitioning the DataFrame\n",
    "dim_customer = df[[\n",
    "    'Customer Id', # primary key\n",
    "    'Customer Fname', \n",
    "    'Customer Lname', \n",
    "    'Customer Email', \n",
    "    'Customer Country',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Customer City', \n",
    "    'Customer State', \n",
    "    'Customer Street', \n",
    "    'Customer Zipcode', \n",
    "    'Customer Segment'\n",
    "]]\n",
    "\n",
    "dim_product = df[[\n",
    "    'Product Card Id', # primary key\n",
    "    'Department Id',\n",
    "    'Department Name',\n",
    "    'Product Category Id',\n",
    "    'Category Name',\n",
    "    'Product Name', \n",
    "    'Product Description', \n",
    "    'Product Price', \n",
    "    'Product Status', \n",
    "]]\n",
    "\n",
    "dim_region = df[[\n",
    "    'Market',\n",
    "    'Order Region',\n",
    "    'Order Country',\n",
    "    'Order State',\n",
    "    'Order City'\n",
    "]].drop_duplicates()\n",
    "\n",
    "dim_shipping = df[[\n",
    "    'Days for shipment (scheduled)', \n",
    "    'Shipping Mode'\n",
    "]]\n",
    "\n",
    "Fact_Sales = df[[\n",
    "    'Customer Id', \n",
    "    'Product Card Id',\n",
    "    'Category Id',\n",
    "    'Order Id', \n",
    "    'Department Id',\n",
    "    'Sales', \n",
    "    'Order Item Quantity',\n",
    "    'Market',\n",
    "    'Order Region',\n",
    "    'Order Country',\n",
    "    'Order State',\n",
    "    'Order City',\n",
    "    'Benefit per order',\n",
    "    'Order Item Cardprod Id',\n",
    "    'Order Item Discount',\n",
    "    'Order Item Product Price',\n",
    "    'Order Item Discount Rate',\n",
    "    'Order Item Profit Ratio',\n",
    "    'Order Profit Per Order',\n",
    "    \"Type\",\n",
    "    'Order Status',\n",
    "    'Order Zipcode',\n",
    "    'order date (DateOrders)',\n",
    "    'Days for shipping (real)',\n",
    "    'shipping date (DateOrders)',\n",
    "    'Delivery Status',\n",
    "    'Late_delivery_risk',\n",
    "    'Days for shipment (scheduled)', \n",
    "    'Shipping Mode'\n",
    "]]\n",
    "\n",
    "date_columns = ['order date (DateOrders)', 'shipping date (DateOrders)']\n",
    "\n",
    "cols_to_drop = [\n",
    "    'Market',\n",
    "    'Order Region',\n",
    "    'Order Country',\n",
    "    'Order State',\n",
    "    'Order City',\n",
    "    'Days for shipment (scheduled)', \n",
    "    'Shipping Mode'\n",
    "]\n",
    "\n",
    "new_cols_order = [\n",
    "    'Customer Id',\n",
    "    'Product Card Id',\n",
    "    'Order Id',\n",
    "    'Region Id',\n",
    "    'Sales',\n",
    "    'Order Item Quantity',\n",
    "    'Benefit per order',\n",
    "    'Order Item Cardprod Id',\n",
    "    'Order Item Discount',\n",
    "    'Order Item Discount Rate',\n",
    "    'Order Item Product Price',\n",
    "    'Order Item Profit Ratio',\n",
    "    'Order Profit Per Order',\n",
    "    'Type',\n",
    "    'Order Status',\n",
    "    'Order Zipcode',\n",
    "    'order date (DateOrders)',\n",
    "    'Days for shipping (real)',\n",
    "    'Shipping Method Id',\n",
    "    'shipping date (DateOrders)',\n",
    "    'Delivery Status',\n",
    "    'Late_delivery_risk'\n",
    "]\n",
    "\n",
    "def generate_region_id(region_df):\n",
    "    \"\"\"\n",
    "    Generates a unique numeric Region Id based on the combination of \n",
    "    Order Region, Order Country, Order State, and Order City.\n",
    "    \n",
    "    Args:\n",
    "    region_df (pd.DataFrame): DataFrame containing the region information.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series containing the unique numeric Region Ids.\n",
    "    \"\"\"\n",
    "    # Create a combined string for each row\n",
    "    combined_strings = (\n",
    "        region_df['Market'].astype(str) + \"_\" +\n",
    "        region_df['Order Region'].astype(str) + \"_\" +\n",
    "        region_df['Order Country'].astype(str) + \"_\" +\n",
    "        region_df['Order State'].astype(str) + \"_\" +\n",
    "        region_df['Order City'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # Generate a consistent hash using hashlib (e.g., SHA-256)\n",
    "    def consistent_hash(value):\n",
    "        # Convert to a SHA-256 hash and take the first 10 digits as an integer\n",
    "        return int(hashlib.sha256(value.encode()).hexdigest(), 16) % (10 ** 10)\n",
    "    \n",
    "    # Apply the consistent hash function to each combined string\n",
    "    region_ids = combined_strings.apply(consistent_hash)\n",
    "    \n",
    "    return region_ids\n",
    "\n",
    "def create_date_dimension(df, date_columns):\n",
    "    \"\"\"\n",
    "    Creates a date dimension DataFrame with a range of dates between the earliest\n",
    "    and latest date in the specified date columns. The output DataFrame includes\n",
    "    datekey, date, year, quarter, month, and weekday.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Input DataFrame containing the date columns.\n",
    "    date_columns (list): List of date columns to consider for the range.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A date dimension DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a copy of df to avoid modifying the original DataFrame directly\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert the specified date columns to datetime\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Get the earliest and latest dates across the specified columns\n",
    "    earliest_date = df[date_columns].min().min()\n",
    "    latest_date = df[date_columns].max().max()\n",
    "\n",
    "    # Generate a date range from earliest to latest date\n",
    "    date_range = pd.date_range(start=earliest_date, end=latest_date)\n",
    "\n",
    "    # Create a DataFrame with the date range\n",
    "    date_df = pd.DataFrame({\n",
    "        'date': date_range\n",
    "    })\n",
    "\n",
    "    # Add additional columns\n",
    "    date_df['datekey'] = date_df['date'].dt.strftime('%m%d%Y').astype(int)  # Date key in mmddyyyy format\n",
    "    date_df['year'] = date_df['date'].dt.year\n",
    "    date_df['quarter'] = date_df['date'].dt.quarter\n",
    "    date_df['month'] = date_df['date'].dt.month\n",
    "    date_df['weekday'] = date_df['date'].dt.weekday  # Monday = 0, Sunday = 6\n",
    "    date_df['weekday_name'] = date_df['date'].dt.day_name() # Add weekday name as a string\n",
    "\n",
    "    return date_df\n",
    "\n",
    "def generate_shipping_method_id(df):\n",
    "    \"\"\"\n",
    "    Generates a unique numeric Shipping Method Id based on the combination of \n",
    "    'Days for shipment (scheduled)' and 'Shipping Mode' using a consistent hash function.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the shipping information.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series containing the unique numeric Shipping Method Ids.\n",
    "    \"\"\"\n",
    "    # Create a combined string for each row\n",
    "    combined_strings = (\n",
    "        df['Days for shipment (scheduled)'].astype(str) + \"_\" +\n",
    "        df['Shipping Mode'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # Generate a consistent hash using hashlib (e.g., SHA-256)\n",
    "    def consistent_hash(value):\n",
    "        # Convert to a SHA-256 hash and take the first 10 digits as an integer\n",
    "        return int(hashlib.sha256(value.encode()).hexdigest(), 16) % (10 ** 10)\n",
    "    \n",
    "    # Apply the consistent hash function to each combined string\n",
    "    shipping_method_ids = combined_strings.apply(consistent_hash)\n",
    "    \n",
    "    return shipping_method_ids\n",
    "\n",
    "\n",
    "\n",
    "def get_date_as_int(df, date_columns):\n",
    "    \"\"\"\n",
    "    Converts the specified date columns from a DataFrame into integer keys\n",
    "    in the mmddyyyy format.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame containing the date columns.\n",
    "    date_columns (list): A list of column names to be converted.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with date columns converted to integer mmddyyyy format.\n",
    "    \"\"\"\n",
    "    for col in date_columns:\n",
    "        # Convert the column to datetime to ensure correct format\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%m/%d/%Y')\n",
    "\n",
    "        # Convert to string in mm/dd/yyyy format\n",
    "        df[col] = df[col].dt.strftime('%m%d%Y')\n",
    "\n",
    "        # Convert to integer for keys\n",
    "        df[col] = df[col].astype(int, errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_columns(df, columns_to_drop):\n",
    "    \"\"\"\n",
    "    Drops the specified columns from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    columns_to_drop (list): A list of column names (strings) to be dropped from the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the specified columns dropped.\n",
    "    \"\"\"\n",
    "    # Drop the columns if they are found in the DataFrame\n",
    "    df_dropped = df.drop(columns=[col for col in columns_to_drop if col in df.columns], axis=1)\n",
    "    \n",
    "    return df_dropped\n",
    "\n",
    "# Keep the first occurrence of each 'Customer Id' (or 'Product Card Id')\n",
    "dim_customer = dim_customer.groupby('Customer Id').first().reset_index()\n",
    "dim_product = dim_product.groupby('Product Card Id').first().reset_index()\n",
    "\n",
    "# Generate Region Ids and insert into dim_region\n",
    "dim_region['Region Id'] = generate_region_id(dim_region)\n",
    "dim_region.insert(0, 'Region Id', dim_region.pop('Region Id'))\n",
    "\n",
    "# Generate dimension date\n",
    "dim_date = create_date_dimension(Fact_Sales, date_columns)\n",
    "\n",
    "# Step 1: Merge dim_region with Fact_Sales to include Region Id\n",
    "Fact_Sales = Fact_Sales.merge(dim_region, how='left',\n",
    "                              on=['Market', 'Order Region', 'Order Country', 'Order State', 'Order City'])\n",
    "\n",
    "Fact_Sales = get_date_as_int(Fact_Sales, date_columns)\n",
    "\n",
    "# Create a copy of dim_shipping for manipulation\n",
    "dim_shipping1 = dim_shipping.copy()\n",
    "\n",
    "# Drop duplicates and generate Shipping Method Id\n",
    "dim_shipping1.drop_duplicates(subset=['Days for shipment (scheduled)', 'Shipping Mode'], inplace=True)\n",
    "dim_shipping1['Shipping Method Id'] = generate_shipping_method_id(dim_shipping1)\n",
    "dim_shipping1.insert(0, 'Shipping Method Id', dim_shipping1.pop('Shipping Method Id'))\n",
    "\n",
    "# Merge Shipping Method Id back into Fact_Sales\n",
    "Fact_Sales = Fact_Sales.merge(dim_shipping1, on=['Days for shipment (scheduled)', 'Shipping Mode'], how='left')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "Fact_Sales = drop_columns(Fact_Sales, cols_to_drop)\n",
    "Fact_Sales = Fact_Sales[new_cols_order]\n",
    "\n",
    "# Step 3: Export to CSV\n",
    "dim_customer.to_csv(os.path.join(processed_data_path, 'dim_customer.csv'), index=False)\n",
    "dim_product.to_csv(os.path.join(processed_data_path, 'dim_product.csv'), index=False)\n",
    "dim_date.to_csv(os.path.join(processed_data_path, 'dim_date.csv'), index=False)\n",
    "dim_shipping1.to_csv(os.path.join(processed_data_path, 'dim_shipping.csv'), index=False)\n",
    "dim_region.to_csv(os.path.join(processed_data_path, 'dim_region.csv'), index=False)\n",
    "Fact_Sales.to_csv(os.path.join(processed_data_path, 'Fact_Sales.csv'), index=False)\n",
    "\n",
    "print(\"CSV files have been exported successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
